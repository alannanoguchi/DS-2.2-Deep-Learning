{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    " 1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    " \n",
    " 2- Normalize data by rescaling them to (0,1) \n",
    " \n",
    " 3- Convert label arrays to 1-hot representation (`keras.utils.to_categorical`)\n",
    " \n",
    " 4- Define Model\n",
    "    * Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "    * Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    * Outout Layer: Fully Connected + Softmax Activition\n",
    " \n",
    " \n",
    "- Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "    1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "    2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "    3. MaxPooling2D(pool_size=(2, 2))\n",
    "    4. Dense(128, activation='relu')\n",
    "    5. Dense(num_classes, activation='softmax')\n",
    "\n",
    "    Also build another model with BatchNormalization and Dropout.\n",
    "    Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt #This package is for plotting\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check a Random Sample of the train data and it's label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "# generate a random number ( use numpy random.randint)\n",
    "rand_num = np.random.randint(60000)\n",
    "\n",
    "#plot using plt.imshow() and plt.show()\n",
    "plt.imshow(x_train[rand_num], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#print its label\n",
    "print('label:', y_train[rand_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Our network accept 1D data so we should flatten our 2D image, then print the dimension of the result arrays:\n",
    "- use numpy reshape function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape x_train and x_test\n",
    "x_train = np.reshape(x_train,[-1, 28*28])\n",
    "x_test = np.reshape(x_test,[-1, 28*28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize data by rescaling them to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/np.max(x_train)\n",
    "x_test = x_test/np.max(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert label arrays to 1-hot representation (keras.utils.to_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Model\n",
    "- Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "- Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "- Outout Layer: Fully Connected + Softmax Activition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))     # each image has 784 pixels because it is 28x28\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining loss function, optimizer and metrics for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.6473 - accuracy: 0.8419 - val_loss: 0.3183 - val_accuracy: 0.9114\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.2969 - accuracy: 0.9161 - val_loss: 0.2611 - val_accuracy: 0.9248\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.2443 - accuracy: 0.9309 - val_loss: 0.2177 - val_accuracy: 0.9394\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                   batch_size=32, \n",
    "                   epochs=3,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.21412893051505089\n",
      "Test accuracy: 0.9386000037193298\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test Loss:', test_score[0])\n",
    "print('Test accuracy:', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "- Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "\n",
    "- Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "\n",
    "- MaxPooling2D(pool_size=(2, 2))\n",
    "\n",
    "- Dense(128, activation='relu')\n",
    "\n",
    "- Dense(num_classes, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1469 - accuracy: 0.9586 - val_loss: 0.1467 - val_accuracy: 0.9597\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1333 - accuracy: 0.9621 - val_loss: 0.1391 - val_accuracy: 0.9611\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 80us/step - loss: 0.1211 - accuracy: 0.9650 - val_loss: 0.1346 - val_accuracy: 0.9622\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes=10\n",
    "\n",
    "cnn_model = Sequential()\n",
    "\n",
    "\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "cnn_model_history = model.fit(x_train, y_train,\n",
    "                   batch_size=32, \n",
    "                   epochs=3,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.12671781725361944\n",
      "Test accuracy: 0.963699996471405\n"
     ]
    }
   ],
   "source": [
    "cnn_test_score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test Loss:', cnn_test_score[0])\n",
    "print('Test accuracy:', cnn_test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also build another model with BatchNormalization and Dropout. Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.1112 - accuracy: 0.9686 - val_loss: 0.1262 - val_accuracy: 0.9651\n",
      "Epoch 2/3\n",
      "48000/48000 [==============================] - 4s 80us/step - loss: 0.1022 - accuracy: 0.9716 - val_loss: 0.1187 - val_accuracy: 0.9671\n",
      "Epoch 3/3\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.0945 - accuracy: 0.9742 - val_loss: 0.1137 - val_accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "\n",
    "final_model = Sequential()\n",
    "\n",
    "\n",
    "final_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "final_model.add(BatchNormalization())\n",
    "\n",
    "final_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "final_model.add(BatchNormalization())\n",
    "final_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "final_model.add(Dropout(0.25))         # dropout\n",
    "\n",
    "final_model.add(Flatten())\n",
    "\n",
    "final_model.add(Dense(128, activation='relu'))\n",
    "final_model.add(BatchNormalization())\n",
    "final_model.add(Dropout(0.5))          # dropout\n",
    "final_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "cnn_model_history = model.fit(x_train, y_train,\n",
    "                   batch_size=32, \n",
    "                   epochs=3,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.10479558789804577\n",
      "Test accuracy: 0.9704999923706055\n"
     ]
    }
   ],
   "source": [
    "final_model_test_score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test Loss:', final_model_test_score[0])\n",
    "print('Test accuracy:', final_model_test_score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
