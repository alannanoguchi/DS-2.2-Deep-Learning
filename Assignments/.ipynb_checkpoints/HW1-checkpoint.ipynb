{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1:\n",
    "\n",
    "1- Build a Keras Model for linear regression (check: https://keras.io/activations/). Use Boston Housing Dataset to train and test your model\n",
    "\n",
    "2- Build a Keras Model for logistic regression. Use diabetes.csv to train and test\n",
    "\n",
    "Comments:\n",
    "\n",
    "1- Build the **simplest model** for linear regression with Keras and compare your model performance with `from sklearn.linear_model import LinearRegression`\n",
    "\n",
    "- do not include any hidden layers! Just have the input and output\n",
    "\n",
    "2- Build the **simplest model** for logistic regression with Keras and compare your model performance with `from sklearn.linear_model import LogisticRegression`\n",
    "- Use these 4 features: feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "3- **Add more complexity to your models in (1) and (2)** and compare with previous results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Linear Regression Model with Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model\n",
    "from sklearn.datasets import load_boston     # import the boston housing dataset\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "# print(boston.DESCR)\n",
    "\n",
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size = 0.30 which is what we want to test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.62864e+00 0.00000e+00 2.18900e+01 ... 2.12000e+01 3.96900e+02\n",
      "  3.44100e+01]\n",
      " [1.14600e-01 2.00000e+01 6.96000e+00 ... 1.86000e+01 3.94960e+02\n",
      "  7.73000e+00]\n",
      " [5.57780e-01 0.00000e+00 2.18900e+01 ... 2.12000e+01 3.94670e+02\n",
      "  1.69600e+01]\n",
      " ...\n",
      " [1.50980e-01 0.00000e+00 1.00100e+01 ... 1.78000e+01 3.94510e+02\n",
      "  1.03000e+01]\n",
      " [2.29270e-01 0.00000e+00 6.91000e+00 ... 1.79000e+01 3.92740e+02\n",
      "  1.88000e+01]\n",
      " [1.39140e-01 0.00000e+00 4.05000e+00 ... 1.66000e+01 3.96900e+02\n",
      "  1.46900e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Build the simplest model for linear regression with Keras with Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Notes:\n",
    "- When we have regression problem\n",
    "\n",
    "    - The loss function should be `mse` or `mae`\n",
    "    - We need one output neuron\n",
    "    - The activation function of last layer can be `linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Squared Error with Keras = 32.71\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(13,))  # 13 features\n",
    "out = Dense(1, activation='linear')(inp)  # 1 layer for simplest model, keras notes: activation = linear\n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "# keras notes: loss function should be mse or mae\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Mean-Squared Error with Keras = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Keras Model with scikit-learns Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the model(Linear Regression) and train it\n",
    "bos_reg = LinearRegression()\n",
    "bos_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.21310401e-01  4.44664254e-02  1.13416945e-02  2.51124642e+00\n",
      " -1.62312529e+01  3.85906801e+00 -9.98516565e-03 -1.50026956e+00\n",
      "  2.42143466e-01 -1.10716124e-02 -1.01775264e+00  6.81446545e-03\n",
      " -4.86738066e-01]\n"
     ]
    }
   ],
   "source": [
    "# coefficient\n",
    "print(bos_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.93710774183255\n"
     ]
    }
   ],
   "source": [
    "# y-intercept\n",
    "print(bos_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using Scikit-learn: 27.195965766883234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = bos_reg.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print('MSE using Scikit-learn: ' + str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertising.csv \u001b[31mdiabetes.csv\u001b[m\u001b[m    pca_uk.xlsx     \u001b[31mspam.csv\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alannanoguchi/dev/DS/DS2.2/DS-2.2-Deep-Learning/Notebooks/Datasets\n"
     ]
    }
   ],
   "source": [
    "%cd Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Logistic Regression Model with Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class notes:\n",
    "\n",
    "- When we have a two class classifcation problem:\n",
    "    - The loss function should be `binary_crossentropy`\n",
    "    - We need one output neuron\n",
    "    - The activation function of last layer would be `sigmoid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "diabetes_data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "# X is a matrix,a ccess the features we want in feature_cols\n",
    "X = diabetes_data[feature_cols]\n",
    "\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = diabetes_data['Outcome']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Build the **simplest model** for logistic regression with Keras using Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.20\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(4,))\n",
    "\n",
    "out = Dense(1, activation='sigmoid')(inp)\n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW correction provided by TA: Andrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.72\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Keras Model with scikit-learns Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with scikit-learn: 69.09722222222221\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy with scikit-learn: ' + str(logreg.score(X_train, y_train)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Add more complexity to your models in (1) and (2) and compare with previous results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added 1 Hidden Layer with 16 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Squared Error with Keras = 37.59\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(13,))  # 13 features\n",
    "\n",
    "# add a hidden layer for complexity\n",
    "x = Dense(16, activation='relu')(inp) \n",
    "out = Dense(1, activation='linear')(x) \n",
    "\n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "# keras notes: loss function should be mse or mae\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Mean-Squared Error with Keras = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added 1 Hidden Layer with 64 neurons-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Squared Error with Keras = 27.04\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(13,))  # 13 features\n",
    "\n",
    "# add a hidden layer for complexity\n",
    "x = Dense(64, activation='relu')(inp) \n",
    "out = Dense(1, activation='linear')(x) \n",
    "\n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "# keras notes: loss function should be mse or mae\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Mean-Squared Error with Keras = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added 2 Hidden Layers with 64 Neurons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Squared Error with Keras = 27.95\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(13,))  # 13 features\n",
    "\n",
    "x = Dense(64, activation='relu')(inp)    # hidden layer 1\n",
    "y = Dense(64, activation='relu')(x)      # hidden layer 2\n",
    "out = Dense(1, activation='linear')(y) \n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "# keras notes: loss function should be mse or mae\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Mean-Squared Error with Keras = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added 1 Hidden Layer with 16 Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.18\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(4,))\n",
    "\n",
    "x = Dense(16, activation='relu')(inp)  \n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added 1 Hidden Layer with 64 Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.19\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(4,))\n",
    "\n",
    "x = Dense(64, activation='relu')(inp)  \n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added 2 Hidden Layers with 64 Neurons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.18\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(4,))\n",
    "\n",
    "x = Dense(64, activation='relu')(inp)\n",
    "y = Dense(64, activation='relu')(x)\n",
    "out = Dense(1, activation='sigmoid')(y)\n",
    "\n",
    "# build the model with inputs at inp and outputs at out\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mean_squared_error'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=0);\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
